{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084b2dda",
   "metadata": {},
   "source": [
    "#    PyTorch Basics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a74c878d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1.Whatâ€™s the difference between PyTorch tensors and NumPy arrays?\n",
    "\n",
    "\n",
    "PyTorch tensors can run on GPU for acceleration; NumPy arrays cannot.\n",
    "\n",
    "PyTorch supports automatic differentiation via autograd; NumPy does not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45309698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1508, 0.7520, 0.3537],\n",
       "        [0.5196, 0.7429, 0.0380]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.# Create a tensor of shape (3, 4) with random values.\n",
    "\n",
    "import torch\n",
    "\n",
    "a=torch.rand(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0403b167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.Create a tensor with all ones and another with all zeros.\n",
    "b=torch.zeros(2,3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d50cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.ones(2,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc4400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 4.Convert a NumPy array to a PyTorch tensor.\n",
    "\n",
    "import numpy as np\n",
    "arr =np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "tensor=torch.from_numpy(arr,de)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eff48ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1409, 0.0837],\n",
       "        [0.2471, 0.0125],\n",
       "        [0.5403, 0.1594]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.Slice a tensor to get the first 2 rows and 2 columns.\n",
    "\n",
    "x=torch.rand(4,4)\n",
    "sliced=x[:3,2:4]\n",
    "sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6467d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7169, -2.0994,  0.4712, -0.8350],\n",
       "        [ 3.4109, -2.8444,  1.1174,  0.2312]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.How do you perform matrix multiplication in PyTorch?\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(3, 4)\n",
    "c = torch.matmul(a, b)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3ffc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.Create a tensor that requires gradients.\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61de8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.])\n"
     ]
    }
   ],
   "source": [
    "# 8. Demonstrate .backward() on a scalar loss.\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 5\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8e6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.])\n"
     ]
    }
   ],
   "source": [
    "# 9.Find the gradient of y = x ** 2 + 3 * x + 5 at x = 3\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 5\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d850d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.Explain .detach() and its use.\n",
    "\"\"\"\n",
    " .detach() creates a new tensor that shares storage but without gradients.\n",
    "\n",
    " \n",
    " Used to stop a tensor from tracking operations in computation graphs.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "y = x * 2\n",
    "y_detached = y.detach()\n",
    "y_detached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc3cd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.How to check if a tensor is on CPU or GPU?\n",
    "\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b27c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.], device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.How to transfer a tensor to GPU?\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3016af2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8537, 0.7834, 0.7244],\n",
       "        [0.6221, 0.3406, 0.4966]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13.What is torch.rand_like() and when would you use it?\n",
    "\n",
    "# It creates a random tensor with the same shape and dtype as the given tensor.\n",
    "\n",
    "ten=torch.ones(2,3)\n",
    "\n",
    "rand=torch.rand_like(ten)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f269fc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14.Create a tensor and clone it. Change the clone and prove the original is unaffected.\n",
    "\n",
    "ten=torch.ones(2,3)\n",
    "\n",
    "ten_copy=ten.clone()\n",
    "\n",
    "ten[0][0]=3\n",
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c64e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdc3b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15.Create a 1D tensor and reshape it into (5, 2).\n",
    "\n",
    "b=torch.arange(1,11,1,device='cuda')\n",
    "b.view(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80d748d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16.What does .unsqueeze() do?\n",
    "'''\n",
    "Adds a dimension of size 1 at a specified position.\n",
    "\n",
    "'''\n",
    "c=torch.tensor([1,2,3,4,5])\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c6ea483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_unsqueeze=c.unsqueeze(1)\n",
    "c_unsqueeze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d754b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_unsqueeze=c.unsqueeze(0)\n",
    "c_unsqueeze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69291d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17.How does broadcasting work in PyTorch?\n",
    "\n",
    "# PyTorch automatically expands tensors to be compatible for element-wise operations without copying data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7438907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18.Add two tensors of different shapes using broadcasting.\n",
    "\n",
    "a=torch.rand(3,1)\n",
    "b=torch.rand(1,4)\n",
    "c=a+b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f0f0202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "[10.]\n"
     ]
    }
   ],
   "source": [
    "# 19.Explain .item() and .numpy() in context of tensors.\n",
    "'''\n",
    ".item() converts a 1-element tensor to a Python scalar.\n",
    "\n",
    ".numpy() converts a CPU tensor to a NumPy array (not allowed on GPU).\n",
    "\n",
    "'''\n",
    "\n",
    "x = torch.tensor([10.0])\n",
    "print(x.item())       # 10.0\n",
    "print(x.numpy())      # array([10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ceca268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.Explain difference between in-place and out-of-place operations with examples.\n",
    "'''\n",
    "In-place: modifies the data directly and has a __ at the end (e.g., .add_())\n",
    "\n",
    "Out-of-place: returns a new tensor, original remains unchanged.\n",
    "\n",
    "'''\n",
    "\n",
    "x = torch.tensor([1.0])\n",
    "x.add_(2)   # in-place\n",
    "# vs\n",
    "x = torch.tensor([1.0])\n",
    "y = x + 2   # out-of-place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edfe87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
